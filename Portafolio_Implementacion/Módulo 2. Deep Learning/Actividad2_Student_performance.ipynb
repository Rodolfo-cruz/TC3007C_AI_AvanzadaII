{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realizado por:** Rodolfo Jesús Cruz Rebollar\n",
    "\n",
    "**Matrícula:** A01368326\n",
    "\n",
    "**Grupo:** 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "You are a data scientist working for a school\n",
    "\n",
    "You are asked to predict the GPA of the current students based on the following provided data: \n",
    "\n",
    " 0   StudentID  int64  \n",
    " 1   Age    int64  \n",
    " 2   Gender int64  \n",
    " 3   Ethnicity  int64  \n",
    " 4   ParentalEducation  int64  \n",
    " 5   StudyTimeWeekly    float64\n",
    " 6   Absences   int64  \n",
    " 7   Tutoring   int64  \n",
    " 8   ParentalSupport    int64  \n",
    " 9   Extracurricular    int64  \n",
    " 10  Sports int64  \n",
    " 11  Music  int64  \n",
    " 12  Volunteering   int64  \n",
    " 13  GPA    float64\n",
    " 14  GradeClass float64\n",
    "\n",
    "The GPA is the Grade Point Average, typically ranges from 0.0 to 4.0 in most educational systems, with 4.0 representing an 'A' or excellent performance.\n",
    "\n",
    "The minimum passing GPA can vary by institution, but it's often around 2.0. This usually corresponds to a 'C' grade, which is considered satisfactory.\n",
    "\n",
    "You need to create a Deep Learning model capable to predict the GPA of a Student based on a set of provided features.\n",
    "The data provided represents 2,392 students.\n",
    "\n",
    "In this excersice you will be requested to create a total of three models and select the most performant one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import Libraries\n",
    "\n",
    "First let's import the following libraries, if there is any library that you need and is not in the list bellow feel free to include it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodolfo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout, SimpleRNN\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load Data\n",
    "\n",
    "- You will be provided with a cvs (comma separated value) file.\n",
    "- You will need to add that file into a pandas dataframe, you can use the following code as reference\n",
    "- The file will be available in canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.042915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054218</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>3388</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.680555</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.455509</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>3389</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.583217</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.279150</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>3390</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.805500</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.142333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>3391</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.416653</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.803297</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>3392</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.819907</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.140014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StudentID  Age  Gender  Ethnicity  ParentalEducation  StudyTimeWeekly  \\\n",
       "0          1001   17       1          0                  2        19.833723   \n",
       "1          1002   18       0          0                  1        15.408756   \n",
       "2          1003   15       0          2                  3         4.210570   \n",
       "3          1004   17       1          0                  3        10.028829   \n",
       "4          1005   17       1          0                  2         4.672495   \n",
       "...         ...  ...     ...        ...                ...              ...   \n",
       "2387       3388   18       1          0                  3        10.680555   \n",
       "2388       3389   17       0          0                  1         7.583217   \n",
       "2389       3390   16       1          0                  2         6.805500   \n",
       "2390       3391   16       1          1                  0        12.416653   \n",
       "2391       3392   16       1          0                  2        17.819907   \n",
       "\n",
       "      Absences  Tutoring  ParentalSupport  Extracurricular  Sports  Music  \\\n",
       "0            7         1                2                0       0      1   \n",
       "1            0         0                1                0       0      0   \n",
       "2           26         0                2                0       0      0   \n",
       "3           14         0                3                1       0      0   \n",
       "4           17         1                3                0       0      0   \n",
       "...        ...       ...              ...              ...     ...    ...   \n",
       "2387         2         0                4                1       0      0   \n",
       "2388         4         1                4                0       1      0   \n",
       "2389        20         0                2                0       0      0   \n",
       "2390        17         0                2                0       1      1   \n",
       "2391        13         0                2                0       0      0   \n",
       "\n",
       "      Volunteering       GPA  GradeClass  \n",
       "0                0  2.929196         2.0  \n",
       "1                0  3.042915         1.0  \n",
       "2                0  0.112602         4.0  \n",
       "3                0  2.054218         3.0  \n",
       "4                0  1.288061         4.0  \n",
       "...            ...       ...         ...  \n",
       "2387             0  3.455509         0.0  \n",
       "2388             0  3.279150         4.0  \n",
       "2389             1  1.142333         2.0  \n",
       "2390             0  1.803297         1.0  \n",
       "2391             1  2.140014         1.0  \n",
       "\n",
       "[2392 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Student_performance_data _.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Review you data:\n",
    "\n",
    "Make sure you review your data.\n",
    "Place special attention of null or empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2392 entries, 0 to 2391\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   StudentID          2392 non-null   int64  \n",
      " 1   Age                2392 non-null   int64  \n",
      " 2   Gender             2392 non-null   int64  \n",
      " 3   Ethnicity          2392 non-null   int64  \n",
      " 4   ParentalEducation  2392 non-null   int64  \n",
      " 5   StudyTimeWeekly    2392 non-null   float64\n",
      " 6   Absences           2392 non-null   int64  \n",
      " 7   Tutoring           2392 non-null   int64  \n",
      " 8   ParentalSupport    2392 non-null   int64  \n",
      " 9   Extracurricular    2392 non-null   int64  \n",
      " 10  Sports             2392 non-null   int64  \n",
      " 11  Music              2392 non-null   int64  \n",
      " 12  Volunteering       2392 non-null   int64  \n",
      " 13  GPA                2392 non-null   float64\n",
      " 14  GradeClass         2392 non-null   float64\n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 280.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove the columns not needed for Student performance prediction\n",
    "\n",
    "- Choose only the columns you consider to be valuable for your model training.\n",
    "- For example, StudentID might not be a good feature for your model, and thus should be removed from your main dataset, which other columns should also be removed?\n",
    "- You can name that final dataset as 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Sports</th>\n",
       "      <th>GradeClass</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.929196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.042915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.112602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.054218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.288061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  ParentalEducation  StudyTimeWeekly  Absences  ParentalSupport  Sports  \\\n",
       "0   17                  2        19.833723         7                2       0   \n",
       "1   18                  1        15.408756         0                1       0   \n",
       "2   15                  3         4.210570        26                2       0   \n",
       "3   17                  3        10.028829        14                3       0   \n",
       "4   17                  2         4.672495        17                3       0   \n",
       "\n",
       "   GradeClass       GPA  \n",
       "0         2.0  2.929196  \n",
       "1         1.0  3.042915  \n",
       "2         4.0  0.112602  \n",
       "3         3.0  2.054218  \n",
       "4         4.0  1.288061  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "\"\"\"Columnas relevantes a seleccionar: Age, ParentalEducation, StudyTimeWeekly, Absenses, \n",
    "   ParentalSupport, Sports, GradeClass, GPA\"\"\"\n",
    "\n",
    "dataset = data.iloc[:, [1, 4, 5, 6, 8, 10, 14, 13]]\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check if the columns has any null values:\n",
    "- Here you now have your final dataset to use in your model training.\n",
    "- Before moving foward review your data check for any null or empty value that might be needed to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                  False\n",
       "ParentalEducation    False\n",
       "StudyTimeWeekly      False\n",
       "Absences             False\n",
       "ParentalSupport      False\n",
       "Sports               False\n",
       "GradeClass           False\n",
       "GPA                  False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Revisar si existen valores nulos o faltantes en cada columna del dataset\n",
    "\n",
    "dataset.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Prepare your data for training and for testing set:\n",
    " - First create a dataset named X, with all columns but GPA. These are the features\n",
    " - Next create another dataset named y, with only GPA column. This is the label\n",
    " - If you go to your Imports, you will see the following import: **'from sklearn.model_selection import train_test_split'**\n",
    " - Use that *train_test_split* function to create: X_train, X_test, y_train and y_test respectively. Use X and y datasets as parameters. Other parameters to use are: Test Size = 0.2, Random State = 42.\n",
    " \n",
    " - Standarize your features (X_train and X_test) by using the StandardScaler (investigate how to use fit_transform and transform functions). This will help the training process by dealing with normilized data.\n",
    "\n",
    " Note: Your X_train shape should be around (1913, 10). This means the dataset has 10 columns which should be the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.37285117,  2.26211643,  1.46815853, ..., -1.9146563 ,\n",
       "         1.51039849,  0.82018081],\n",
       "       [-0.40585814,  0.23853507, -1.27677348, ..., -1.02021491,\n",
       "        -0.66207693,  0.82018081],\n",
       "       [ 0.48349652,  1.25032575, -1.10363153, ..., -1.9146563 ,\n",
       "        -0.66207693,  0.82018081],\n",
       "       ...,\n",
       "       [-0.40585814,  0.23853507, -1.08325424, ..., -0.12577352,\n",
       "         1.51039849,  0.01141489],\n",
       "       [ 1.37285117,  0.23853507, -0.93767144, ...,  0.76866788,\n",
       "        -0.66207693,  0.82018081],\n",
       "       [ 1.37285117,  0.23853507, -0.7578795 , ..., -0.12577352,\n",
       "        -0.66207693,  0.82018081]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Dataset solo con variables predictoras sin la variable respuesta GPA\n",
    "\n",
    "X = dataset.iloc[:, :7]\n",
    "\n",
    "# Dataset solo con la variable respuesta GPA\n",
    "\n",
    "y = dataset[\"GPA\"]\n",
    "\n",
    "# Crear conjuntos de entrenamiento y prueba para X, y\n",
    "\n",
    "# Destinar 20% de los datos para probar el modelo y el 80% sobrante para entrenarlo\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "# Estandarizar/normalizar los valores de las variables sin considerar a la variable respuesta (GPA)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "std_features = scaler.fit_transform(X_train, X_test)\n",
    "\n",
    "std_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define your Deep Neural Network.\n",
    "- This will be a Sequential Neural Network.\n",
    "- With a Dense input layer with 64 units, and input dimention of 10 and Relu as the activation function.\n",
    "- A Dense hidden layer with 32 units, and Relu as the activation function.\n",
    "- And a Dense output layer with 1 unit, do not define an activation function so it defaults to linear, suitable for regression tasks. e.g. Dense(1)\n",
    "\n",
    "This last part of the output layer is super important, since we want to predict the GPA, this means that we want a regression and not a classification. Linear activation function is best for regression and Sigmoid is best for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodolfo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Crear Red Neuronal secuencial\n",
    "\n",
    "SNN = Sequential()\n",
    "\n",
    "# Agregar dense input layer de 64 unidades, definir Relu como función de activación y dimensión de entrada igual a 7\n",
    "\n",
    "SNN.add(Dense(64, activation=\"relu\", input_dim = 7))\n",
    "\n",
    "# Agregar una capa oculta más con 32 unidades y función de activación Relu\n",
    "\n",
    "SNN.add(Dense(32, activation=\"relu\"))\n",
    "\n",
    "# Añadir capa de salida con 1 unidad \n",
    "\n",
    "SNN.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Compile your Neural Network\n",
    "- Choose Adam as the optimizer\n",
    "- And MSE as the Loss function\n",
    "- Also add the following metrics: Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "SNN.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Fit (or train) your model\n",
    "- Use the X_train and y_train datasets for the training\n",
    "- Do 50 data iterations\n",
    "- Choose the batch size = 10\n",
    "- Also select a validation_split of 0.2\n",
    "- Save the result of the fit function in a variable called 'history'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.9150 - mae: 0.9499 - val_loss: 0.1374 - val_mae: 0.2971\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1245 - mae: 0.2853 - val_loss: 0.1370 - val_mae: 0.2965\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1145 - mae: 0.2721 - val_loss: 0.1024 - val_mae: 0.2596\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1003 - mae: 0.2566 - val_loss: 0.1053 - val_mae: 0.2624\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0988 - mae: 0.2541 - val_loss: 0.1040 - val_mae: 0.2637\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0900 - mae: 0.2439 - val_loss: 0.0968 - val_mae: 0.2505\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0836 - mae: 0.2320 - val_loss: 0.1023 - val_mae: 0.2588\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0869 - mae: 0.2364 - val_loss: 0.1055 - val_mae: 0.2657\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0883 - mae: 0.2376 - val_loss: 0.0996 - val_mae: 0.2565\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0781 - mae: 0.2228 - val_loss: 0.1094 - val_mae: 0.2667\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0829 - mae: 0.2315 - val_loss: 0.0953 - val_mae: 0.2521\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0826 - mae: 0.2337 - val_loss: 0.0997 - val_mae: 0.2563\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0765 - mae: 0.2228 - val_loss: 0.0891 - val_mae: 0.2400\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0862 - mae: 0.2370 - val_loss: 0.1041 - val_mae: 0.2610\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0869 - mae: 0.2387 - val_loss: 0.0875 - val_mae: 0.2372\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0764 - mae: 0.2240 - val_loss: 0.0880 - val_mae: 0.2399\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0743 - mae: 0.2188 - val_loss: 0.1057 - val_mae: 0.2618\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0802 - mae: 0.2231 - val_loss: 0.0823 - val_mae: 0.2301\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0723 - mae: 0.2197 - val_loss: 0.0876 - val_mae: 0.2371\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0787 - mae: 0.2226 - val_loss: 0.0771 - val_mae: 0.2228\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0715 - mae: 0.2152 - val_loss: 0.0847 - val_mae: 0.2367\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0791 - mae: 0.2255 - val_loss: 0.0994 - val_mae: 0.2590\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0676 - mae: 0.2108 - val_loss: 0.0782 - val_mae: 0.2249\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0688 - mae: 0.2110 - val_loss: 0.0899 - val_mae: 0.2418\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0762 - mae: 0.2174 - val_loss: 0.0899 - val_mae: 0.2433\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0688 - mae: 0.2100 - val_loss: 0.0755 - val_mae: 0.2217\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0672 - mae: 0.2056 - val_loss: 0.0799 - val_mae: 0.2280\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0678 - mae: 0.2079 - val_loss: 0.0772 - val_mae: 0.2215\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0656 - mae: 0.2054 - val_loss: 0.0841 - val_mae: 0.2358\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0736 - mae: 0.2208 - val_loss: 0.0775 - val_mae: 0.2243\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0628 - mae: 0.1994 - val_loss: 0.0948 - val_mae: 0.2477\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0692 - mae: 0.2115 - val_loss: 0.0720 - val_mae: 0.2171\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0625 - mae: 0.1998 - val_loss: 0.0734 - val_mae: 0.2179\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0633 - mae: 0.1994 - val_loss: 0.0753 - val_mae: 0.2201\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0627 - mae: 0.1993 - val_loss: 0.1266 - val_mae: 0.2933\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0716 - mae: 0.2142 - val_loss: 0.0687 - val_mae: 0.2096\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0581 - mae: 0.1897 - val_loss: 0.0672 - val_mae: 0.2069\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0563 - mae: 0.1890 - val_loss: 0.0874 - val_mae: 0.2400\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0599 - mae: 0.1950 - val_loss: 0.0792 - val_mae: 0.2247\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0682 - mae: 0.2052 - val_loss: 0.0694 - val_mae: 0.2107\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0604 - mae: 0.1958 - val_loss: 0.0793 - val_mae: 0.2276\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0600 - mae: 0.1929 - val_loss: 0.0732 - val_mae: 0.2170\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0636 - mae: 0.2001 - val_loss: 0.0662 - val_mae: 0.2054\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0641 - mae: 0.2016 - val_loss: 0.0680 - val_mae: 0.2070\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0650 - mae: 0.2036 - val_loss: 0.0809 - val_mae: 0.2295\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0554 - mae: 0.1896 - val_loss: 0.0680 - val_mae: 0.2087\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0541 - mae: 0.1853 - val_loss: 0.0644 - val_mae: 0.2032\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0606 - mae: 0.1955 - val_loss: 0.0723 - val_mae: 0.2180\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0526 - mae: 0.1838 - val_loss: 0.0677 - val_mae: 0.2064\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0535 - mae: 0.1834 - val_loss: 0.0611 - val_mae: 0.1972\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "history = SNN.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. View your history variable:\n",
    "- Use Matplotlib.pyplot to show graphs of your model traning history\n",
    "- In one graph:\n",
    "   - Plot the Training Loss and the Validation Loss\n",
    "   - X Label = Epochs\n",
    "   - Y Label = Loss\n",
    "   - Title = Training and Validation Loss over Epochs\n",
    "- In a second graph:\n",
    "   - Plot the Training MAE and the Validation MAE\n",
    "   - X Label = Epochs\n",
    "   - Y Label = Mean Absolute Error (MAE)\n",
    "   - Title = Training and Validation MAE over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfico de tamaño 10 x 8\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Gráfica de la función de pérdida en el entrenamiento durante 50 épocas o iteraciones\n",
    "\n",
    "plt.plot(range(1, 51), history.history[\"loss\"], linewidth = 2, marker = \"o\", label = \"Training Loss\", color = \"red\")\n",
    "\n",
    "# Gráfica de función de pérdida en la validación durante 50 épocas\n",
    "\n",
    "plt.plot(range(1, 51), history.history[\"val_loss\"], linewidth = 2, marker = \"o\", label = \"Validation Loss\", color = \"blue\")\n",
    "\n",
    "# Eje x: número de época\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "# Eje Y: valores de la función de pérdida\n",
    "\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Título del gráfico\n",
    "\n",
    "plt.title(\"Training and Validation Loss over Epochs\")\n",
    "\n",
    "# Leyenda\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar gráfico\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Gráfico de tamaño 10 x 8\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Gráfica del MAE en el entrenamiento durante 50 épocas o iteraciones\n",
    "\n",
    "plt.plot(range(1, 51), history.history[\"mae\"], linewidth = 2, marker = \"o\", label = \"Training MAE\", color = \"green\")\n",
    "\n",
    "# Gráfica del MAE en la validación durante 50 épocas\n",
    "\n",
    "plt.plot(range(1, 51), history.history[\"val_mae\"], linewidth = 2, marker = \"o\", label = \"Validation MAE\", color = \"magenta\")\n",
    "\n",
    "# Eje x: número de época\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "# Eje Y: valores de la función de pérdida\n",
    "\n",
    "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
    "\n",
    "# Título del gráfico\n",
    "\n",
    "plt.title(\"Training and Validation MAE over Epochs\")\n",
    "\n",
    "# Leyenda\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar gráfico\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Evaluate your model:\n",
    "- See the result of your loss function.\n",
    "- What can you deduct from there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0628 - mae: 0.1842 \n",
      "Loss values: [0.057948123663663864, 0.18323682248592377]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "loss_evaluation = SNN.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Loss values: {loss_evaluation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el resultado anterior es posible observar que al final del proceso de evaluación del modelo, el valor final de la función de pérdida es de 0.0628, mientras que el valor final del MAE es de 0.1842, los cuales son valores mayormente bajos, lo cual indica que al final de todo el proceso, el modelo generado resulta ser bastante bueno, lo cual se encuentra también respaldado por el hecho de que los valores finales de pérdida (0.0579 y 0.1832) son también mayormente bajos, por lo cual, en base a lo anterior, es posible afirmar que las predicciones del GPA derivadas del modelo tendrán un elevado grado de precisión, por lo cual, serán bastante cercanas a los valores reales del GPA, indicando que el modelo generado es en su mayoría adecuado para predecir el valor del GPA para los alumnos en cuestión. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Use your model to make some predictions:\n",
    "- Make predictions of your X_test dataset\n",
    "- Print the each of the predictions and the actual value (which is in y_test)\n",
    "- How good was your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1.427724</td>\n",
       "      <td>1.409159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3.117354</td>\n",
       "      <td>3.204351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>2.037769</td>\n",
       "      <td>1.999401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>3.548521</td>\n",
       "      <td>3.660019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.248977</td>\n",
       "      <td>0.453828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1.562360</td>\n",
       "      <td>1.966774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2.174903</td>\n",
       "      <td>2.229356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2.332540</td>\n",
       "      <td>2.434402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>2.777967</td>\n",
       "      <td>2.639778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>0.863545</td>\n",
       "      <td>0.935799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Real  Predicted\n",
       "1004  1.427724   1.409159\n",
       "196   3.117354   3.204351\n",
       "2342  2.037769   1.999401\n",
       "1708  3.548521   3.660019\n",
       "435   0.248977   0.453828\n",
       "...        ...        ...\n",
       "986   1.562360   1.966774\n",
       "120   2.174903   2.229356\n",
       "283   2.332540   2.434402\n",
       "1740  2.777967   2.639778\n",
       "1726  0.863545   0.935799\n",
       "\n",
       "[479 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "GPA_predicted = SNN.predict(X_test)\n",
    "\n",
    "pred_real = pd.DataFrame({\"Real\": y_test, \"Predicted\": np.reshape(GPA_predicted, len(GPA_predicted))})\n",
    "\n",
    "pred_real.reset_index(drop = True, inplace = True)\n",
    "\n",
    "pred_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En términos generales, el modelo resulta ser bastante bueno, porque en el dataframe de datos reales contra predicciones se aprecia que existen diferencias mayormente pequeñas entre los valores reales del GPA y los predichos por el modelo, lo cual respalda el hecho de que el modelo posea valores mayormente bajos de pérdida (MSE) y de MAE, por lo que tomando esto en consideración, es posible afirmar que el modelo en cuestión es mayormente adecuado para predecir el GPA de los estudiantes de una manera mayormente precisa y por lo tanto también confiable, tomando en cuenta algunos atributos o cualidades mayormente relevantes del alumnado en general. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Compete against this model:\n",
    "- Create two more different models to compete with this model\n",
    "- Here are a few ideas of things you can change:\n",
    "   - During Dataset data engineering:\n",
    "      - You can remove features that you think do not help in the training and prediction \n",
    "      - Feature Scaling: Ensure all features are on a similar scale (as you already did with StandardScaler)\n",
    "   - During Model Definition:\n",
    "      - You can change the Model Architecture (change the type or number of layers or the number of units)\n",
    "      - You can add dropout layers to prevent overfitting\n",
    "   - During Model Compile:\n",
    "      - You can try other optimizer when compiling your model, here some optimizer samples: Adam, RMSprop, or Adagrad.\n",
    "      - Try another Loss Function\n",
    "   - During Model Training:\n",
    "      - Encrease the number of Epochs\n",
    "      - Adjust the size of your batch\n",
    "- Explain in a Markdown cell which changes are you implementing\n",
    "- Show the comparison of your model versus the original model\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "- Cambios implementados:\n",
    "   - Model Definition: el nuevo modelo será una red secuencial, esta vez la primer capa tendrá 96 unidades y además\n",
    "   habrá otra capa oculta adicional con 48 unidades. \n",
    "\n",
    "   - Model Compile: el nuevo modelo utilizará un optimizador de tipo RMSprop en lugar de Adam. \n",
    "\n",
    "   - Model Training: el nuevo modelo será entrenado con un total de 100 épocas o iteraciones en lugar de 50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rodolfo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Crear red neuronal secuencial\n",
    "\n",
    "modelo2 = Sequential()\n",
    "\n",
    "# Agregar una capa Dense con 96 unidades y una función de activación Relu\n",
    "\n",
    "modelo2.add(Dense(96, activation=\"relu\", input_dim = 7))\n",
    "\n",
    "# Agregar una capa oculta adicional con 48 unidades y función de activación Relu\n",
    "\n",
    "modelo2.add(Dense(48, activation = \"relu\"))\n",
    "\n",
    "# Añadir capa de salida\n",
    "\n",
    "modelo2.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo utilizando en esta ocasión, el optimizador de tipo RMSprop\n",
    "\n",
    "modelo2.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0849 - mae: 0.6298 - val_loss: 0.3280 - val_mae: 0.4841\n",
      "Epoch 2/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2001 - mae: 0.3611 - val_loss: 0.1464 - val_mae: 0.3138\n",
      "Epoch 3/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1576 - mae: 0.3181 - val_loss: 0.1976 - val_mae: 0.3644\n",
      "Epoch 4/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1341 - mae: 0.2937 - val_loss: 0.1253 - val_mae: 0.2834\n",
      "Epoch 5/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1308 - mae: 0.2889 - val_loss: 0.1064 - val_mae: 0.2625\n",
      "Epoch 6/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1280 - mae: 0.2871 - val_loss: 0.1044 - val_mae: 0.2589\n",
      "Epoch 7/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1260 - mae: 0.2837 - val_loss: 0.1407 - val_mae: 0.3049\n",
      "Epoch 8/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1102 - mae: 0.2652 - val_loss: 0.1053 - val_mae: 0.2623\n",
      "Epoch 9/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1089 - mae: 0.2679 - val_loss: 0.1887 - val_mae: 0.3610\n",
      "Epoch 10/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0966 - mae: 0.2491 - val_loss: 0.0966 - val_mae: 0.2529\n",
      "Epoch 11/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0963 - mae: 0.2492 - val_loss: 0.1179 - val_mae: 0.2753\n",
      "Epoch 12/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1013 - mae: 0.2518 - val_loss: 0.0990 - val_mae: 0.2531\n",
      "Epoch 13/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0907 - mae: 0.2438 - val_loss: 0.0963 - val_mae: 0.2510\n",
      "Epoch 14/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0927 - mae: 0.2416 - val_loss: 0.1406 - val_mae: 0.3035\n",
      "Epoch 15/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0835 - mae: 0.2342 - val_loss: 0.1393 - val_mae: 0.3020\n",
      "Epoch 16/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0880 - mae: 0.2403 - val_loss: 0.0888 - val_mae: 0.2397\n",
      "Epoch 17/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0817 - mae: 0.2327 - val_loss: 0.0939 - val_mae: 0.2494\n",
      "Epoch 18/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0787 - mae: 0.2254 - val_loss: 0.0946 - val_mae: 0.2472\n",
      "Epoch 19/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0811 - mae: 0.2292 - val_loss: 0.0812 - val_mae: 0.2271\n",
      "Epoch 20/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0744 - mae: 0.2172 - val_loss: 0.0973 - val_mae: 0.2550\n",
      "Epoch 21/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0804 - mae: 0.2279 - val_loss: 0.1249 - val_mae: 0.2909\n",
      "Epoch 22/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0782 - mae: 0.2229 - val_loss: 0.1088 - val_mae: 0.2642\n",
      "Epoch 23/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0777 - mae: 0.2228 - val_loss: 0.0900 - val_mae: 0.2459\n",
      "Epoch 24/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0737 - mae: 0.2131 - val_loss: 0.0769 - val_mae: 0.2246\n",
      "Epoch 25/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0740 - mae: 0.2196 - val_loss: 0.0846 - val_mae: 0.2346\n",
      "Epoch 26/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0736 - mae: 0.2160 - val_loss: 0.0758 - val_mae: 0.2211\n",
      "Epoch 27/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0746 - mae: 0.2211 - val_loss: 0.0745 - val_mae: 0.2196\n",
      "Epoch 28/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0693 - mae: 0.2124 - val_loss: 0.0782 - val_mae: 0.2256\n",
      "Epoch 29/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0654 - mae: 0.2047 - val_loss: 0.0731 - val_mae: 0.2153\n",
      "Epoch 30/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0681 - mae: 0.2091 - val_loss: 0.0723 - val_mae: 0.2149\n",
      "Epoch 31/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0706 - mae: 0.2119 - val_loss: 0.0817 - val_mae: 0.2359\n",
      "Epoch 32/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0659 - mae: 0.2045 - val_loss: 0.0879 - val_mae: 0.2371\n",
      "Epoch 33/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0664 - mae: 0.2048 - val_loss: 0.0823 - val_mae: 0.2344\n",
      "Epoch 34/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0658 - mae: 0.2064 - val_loss: 0.0748 - val_mae: 0.2172\n",
      "Epoch 35/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0641 - mae: 0.2014 - val_loss: 0.0860 - val_mae: 0.2385\n",
      "Epoch 36/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0615 - mae: 0.1959 - val_loss: 0.0761 - val_mae: 0.2238\n",
      "Epoch 37/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0574 - mae: 0.1946 - val_loss: 0.0912 - val_mae: 0.2410\n",
      "Epoch 38/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0616 - mae: 0.1987 - val_loss: 0.0678 - val_mae: 0.2062\n",
      "Epoch 39/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0630 - mae: 0.2021 - val_loss: 0.0812 - val_mae: 0.2347\n",
      "Epoch 40/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0595 - mae: 0.1929 - val_loss: 0.0763 - val_mae: 0.2257\n",
      "Epoch 41/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0603 - mae: 0.1924 - val_loss: 0.0616 - val_mae: 0.1982\n",
      "Epoch 42/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0587 - mae: 0.1936 - val_loss: 0.0670 - val_mae: 0.2073\n",
      "Epoch 43/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0621 - mae: 0.1962 - val_loss: 0.0754 - val_mae: 0.2230\n",
      "Epoch 44/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0574 - mae: 0.1900 - val_loss: 0.0797 - val_mae: 0.2341\n",
      "Epoch 45/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0519 - mae: 0.1818 - val_loss: 0.0702 - val_mae: 0.2174\n",
      "Epoch 46/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0548 - mae: 0.1856 - val_loss: 0.0789 - val_mae: 0.2253\n",
      "Epoch 47/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0573 - mae: 0.1888 - val_loss: 0.0674 - val_mae: 0.2123\n",
      "Epoch 48/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0569 - mae: 0.1913 - val_loss: 0.0643 - val_mae: 0.2032\n",
      "Epoch 49/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0558 - mae: 0.1895 - val_loss: 0.0662 - val_mae: 0.2095\n",
      "Epoch 50/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0537 - mae: 0.1862 - val_loss: 0.0635 - val_mae: 0.1998\n",
      "Epoch 51/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0564 - mae: 0.1862 - val_loss: 0.0717 - val_mae: 0.2220\n",
      "Epoch 52/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0554 - mae: 0.1861 - val_loss: 0.0632 - val_mae: 0.1983\n",
      "Epoch 53/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0549 - mae: 0.1854 - val_loss: 0.0861 - val_mae: 0.2441\n",
      "Epoch 54/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0568 - mae: 0.1907 - val_loss: 0.0695 - val_mae: 0.2085\n",
      "Epoch 55/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0548 - mae: 0.1862 - val_loss: 0.0824 - val_mae: 0.2412\n",
      "Epoch 56/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0573 - mae: 0.1881 - val_loss: 0.0847 - val_mae: 0.2431\n",
      "Epoch 57/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0512 - mae: 0.1812 - val_loss: 0.0619 - val_mae: 0.1987\n",
      "Epoch 58/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0515 - mae: 0.1780 - val_loss: 0.0633 - val_mae: 0.2009\n",
      "Epoch 59/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0507 - mae: 0.1783 - val_loss: 0.0593 - val_mae: 0.1915\n",
      "Epoch 60/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0522 - mae: 0.1813 - val_loss: 0.0653 - val_mae: 0.2047\n",
      "Epoch 61/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0514 - mae: 0.1777 - val_loss: 0.0595 - val_mae: 0.1969\n",
      "Epoch 62/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0533 - mae: 0.1807 - val_loss: 0.0620 - val_mae: 0.1972\n",
      "Epoch 63/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0501 - mae: 0.1757 - val_loss: 0.0551 - val_mae: 0.1864\n",
      "Epoch 64/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0498 - mae: 0.1748 - val_loss: 0.0643 - val_mae: 0.2062\n",
      "Epoch 65/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0504 - mae: 0.1765 - val_loss: 0.0731 - val_mae: 0.2140\n",
      "Epoch 66/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0520 - mae: 0.1764 - val_loss: 0.0696 - val_mae: 0.2179\n",
      "Epoch 67/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0513 - mae: 0.1797 - val_loss: 0.0619 - val_mae: 0.2027\n",
      "Epoch 68/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0483 - mae: 0.1752 - val_loss: 0.0722 - val_mae: 0.2226\n",
      "Epoch 69/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0466 - mae: 0.1699 - val_loss: 0.0567 - val_mae: 0.1873\n",
      "Epoch 70/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0490 - mae: 0.1752 - val_loss: 0.0618 - val_mae: 0.2005\n",
      "Epoch 71/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0474 - mae: 0.1735 - val_loss: 0.0564 - val_mae: 0.1862\n",
      "Epoch 72/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0468 - mae: 0.1714 - val_loss: 0.0688 - val_mae: 0.2086\n",
      "Epoch 73/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0496 - mae: 0.1774 - val_loss: 0.0582 - val_mae: 0.1916\n",
      "Epoch 74/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0463 - mae: 0.1711 - val_loss: 0.0587 - val_mae: 0.1902\n",
      "Epoch 75/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0502 - mae: 0.1774 - val_loss: 0.0646 - val_mae: 0.1994\n",
      "Epoch 76/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0473 - mae: 0.1729 - val_loss: 0.0576 - val_mae: 0.1906\n",
      "Epoch 77/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0500 - mae: 0.1774 - val_loss: 0.0544 - val_mae: 0.1833\n",
      "Epoch 78/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0484 - mae: 0.1750 - val_loss: 0.0542 - val_mae: 0.1809\n",
      "Epoch 79/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0471 - mae: 0.1720 - val_loss: 0.0556 - val_mae: 0.1860\n",
      "Epoch 80/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0471 - mae: 0.1709 - val_loss: 0.0615 - val_mae: 0.2017\n",
      "Epoch 81/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0451 - mae: 0.1664 - val_loss: 0.0751 - val_mae: 0.2216\n",
      "Epoch 82/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0476 - mae: 0.1719 - val_loss: 0.0605 - val_mae: 0.1956\n",
      "Epoch 83/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0455 - mae: 0.1686 - val_loss: 0.0682 - val_mae: 0.2095\n",
      "Epoch 84/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0440 - mae: 0.1657 - val_loss: 0.0546 - val_mae: 0.1867\n",
      "Epoch 85/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0429 - mae: 0.1629 - val_loss: 0.0560 - val_mae: 0.1869\n",
      "Epoch 86/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0465 - mae: 0.1717 - val_loss: 0.0634 - val_mae: 0.1991\n",
      "Epoch 87/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0458 - mae: 0.1673 - val_loss: 0.0713 - val_mae: 0.2082\n",
      "Epoch 88/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0493 - mae: 0.1761 - val_loss: 0.0529 - val_mae: 0.1833\n",
      "Epoch 89/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0452 - mae: 0.1680 - val_loss: 0.0754 - val_mae: 0.2139\n",
      "Epoch 90/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0469 - mae: 0.1705 - val_loss: 0.0849 - val_mae: 0.2370\n",
      "Epoch 91/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0456 - mae: 0.1703 - val_loss: 0.0686 - val_mae: 0.2050\n",
      "Epoch 92/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0454 - mae: 0.1681 - val_loss: 0.0528 - val_mae: 0.1820\n",
      "Epoch 93/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0440 - mae: 0.1672 - val_loss: 0.0543 - val_mae: 0.1813\n",
      "Epoch 94/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0441 - mae: 0.1642 - val_loss: 0.0737 - val_mae: 0.2227\n",
      "Epoch 95/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0454 - mae: 0.1662 - val_loss: 0.0530 - val_mae: 0.1797\n",
      "Epoch 96/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0434 - mae: 0.1609 - val_loss: 0.0584 - val_mae: 0.1896\n",
      "Epoch 97/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0419 - mae: 0.1593 - val_loss: 0.0652 - val_mae: 0.1969\n",
      "Epoch 98/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0434 - mae: 0.1637 - val_loss: 0.0566 - val_mae: 0.1890\n",
      "Epoch 99/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0460 - mae: 0.1683 - val_loss: 0.0575 - val_mae: 0.1894\n",
      "Epoch 100/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0410 - mae: 0.1576 - val_loss: 0.0603 - val_mae: 0.1970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ac63d3b8b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo 2 con 100 épocas\n",
    "\n",
    "modelo2.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0658 - mae: 0.1924 \n",
      "loss values modelo 2: [0.05936802551150322, 0.1850443184375763]\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el segundo modelo entrenado con 100 épocas\n",
    "\n",
    "eval_m2 = modelo2.evaluate(X_test, y_test)\n",
    "\n",
    "# Desplegar los mejores valores de pérdida y de MAE del modelo 2\n",
    "\n",
    "print(f'loss values modelo 2: {eval_m2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3:\n",
    "- Cambios implementados:\n",
    "   - Model Definition: el nuevo modelo será una red secuencial, esta vez la primer capa tendrá 128 unidades y además\n",
    "   habrá otra capa oculta adicional con 64 unidades. \n",
    "\n",
    "   - Model Compile: el nuevo modelo utilizará un optimizador de tipo Adagrad en lugar de Adam. \n",
    "\n",
    "   - Model Training: el nuevo modelo será entrenado con un total de 150 épocas o iteraciones en lugar de 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Crear 3er modelo de red neuronal secuencial\n",
    "\n",
    "modelo3 = Sequential()\n",
    "\n",
    "# Agregar la primer capa Dense con 128 unidades y una función de activación de tipo Relu\n",
    "\n",
    "modelo3.add(Dense(128, activation=\"relu\", input_dim = 7))\n",
    "\n",
    "# Agregar capa oculta extra con 64 unidades igualmente con una función de activación Relu\n",
    "\n",
    "modelo3.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "# Agregar capa de salida para efectuar predicciones\n",
    "\n",
    "modelo3.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo con capas de 128 y 64 unidades respectivamente, optimizador Adagrad y métrica MAE\n",
    "\n",
    "modelo3.compile(optimizer=\"adagrad\", loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6031 - mae: 0.5777 - val_loss: 0.1729 - val_mae: 0.3329\n",
      "Epoch 2/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1543 - mae: 0.3187 - val_loss: 0.1381 - val_mae: 0.2982\n",
      "Epoch 3/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1221 - mae: 0.2832 - val_loss: 0.1279 - val_mae: 0.2882\n",
      "Epoch 4/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1166 - mae: 0.2787 - val_loss: 0.1199 - val_mae: 0.2794\n",
      "Epoch 5/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1081 - mae: 0.2705 - val_loss: 0.1198 - val_mae: 0.2786\n",
      "Epoch 6/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1031 - mae: 0.2599 - val_loss: 0.1145 - val_mae: 0.2727\n",
      "Epoch 7/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1011 - mae: 0.2574 - val_loss: 0.1108 - val_mae: 0.2680\n",
      "Epoch 8/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0999 - mae: 0.2567 - val_loss: 0.1096 - val_mae: 0.2663\n",
      "Epoch 9/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0927 - mae: 0.2485 - val_loss: 0.1072 - val_mae: 0.2636\n",
      "Epoch 10/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0966 - mae: 0.2511 - val_loss: 0.1094 - val_mae: 0.2661\n",
      "Epoch 11/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0964 - mae: 0.2524 - val_loss: 0.1057 - val_mae: 0.2614\n",
      "Epoch 12/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0937 - mae: 0.2496 - val_loss: 0.1055 - val_mae: 0.2614\n",
      "Epoch 13/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0961 - mae: 0.2512 - val_loss: 0.1064 - val_mae: 0.2625\n",
      "Epoch 14/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0935 - mae: 0.2488 - val_loss: 0.1071 - val_mae: 0.2642\n",
      "Epoch 15/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0904 - mae: 0.2452 - val_loss: 0.1052 - val_mae: 0.2609\n",
      "Epoch 16/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0882 - mae: 0.2418 - val_loss: 0.1045 - val_mae: 0.2594\n",
      "Epoch 17/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0895 - mae: 0.2403 - val_loss: 0.1041 - val_mae: 0.2596\n",
      "Epoch 18/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0882 - mae: 0.2407 - val_loss: 0.1048 - val_mae: 0.2609\n",
      "Epoch 19/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0883 - mae: 0.2393 - val_loss: 0.1046 - val_mae: 0.2598\n",
      "Epoch 20/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0866 - mae: 0.2381 - val_loss: 0.1037 - val_mae: 0.2585\n",
      "Epoch 21/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0970 - mae: 0.2525 - val_loss: 0.1030 - val_mae: 0.2578\n",
      "Epoch 22/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0901 - mae: 0.2431 - val_loss: 0.1046 - val_mae: 0.2584\n",
      "Epoch 23/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0929 - mae: 0.2471 - val_loss: 0.1031 - val_mae: 0.2580\n",
      "Epoch 24/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0909 - mae: 0.2421 - val_loss: 0.1044 - val_mae: 0.2609\n",
      "Epoch 25/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0866 - mae: 0.2389 - val_loss: 0.1035 - val_mae: 0.2581\n",
      "Epoch 26/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0874 - mae: 0.2413 - val_loss: 0.1032 - val_mae: 0.2586\n",
      "Epoch 27/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0922 - mae: 0.2441 - val_loss: 0.1040 - val_mae: 0.2603\n",
      "Epoch 28/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0862 - mae: 0.2362 - val_loss: 0.1031 - val_mae: 0.2573\n",
      "Epoch 29/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0821 - mae: 0.2331 - val_loss: 0.1018 - val_mae: 0.2560\n",
      "Epoch 30/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0857 - mae: 0.2391 - val_loss: 0.1027 - val_mae: 0.2583\n",
      "Epoch 31/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0865 - mae: 0.2394 - val_loss: 0.1030 - val_mae: 0.2587\n",
      "Epoch 32/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0890 - mae: 0.2413 - val_loss: 0.1020 - val_mae: 0.2569\n",
      "Epoch 33/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0824 - mae: 0.2309 - val_loss: 0.1069 - val_mae: 0.2654\n",
      "Epoch 34/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0857 - mae: 0.2342 - val_loss: 0.1029 - val_mae: 0.2591\n",
      "Epoch 35/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0899 - mae: 0.2448 - val_loss: 0.1031 - val_mae: 0.2595\n",
      "Epoch 36/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0855 - mae: 0.2379 - val_loss: 0.1013 - val_mae: 0.2558\n",
      "Epoch 37/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0828 - mae: 0.2352 - val_loss: 0.1021 - val_mae: 0.2579\n",
      "Epoch 38/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0882 - mae: 0.2426 - val_loss: 0.1016 - val_mae: 0.2565\n",
      "Epoch 39/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0908 - mae: 0.2458 - val_loss: 0.1015 - val_mae: 0.2562\n",
      "Epoch 40/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0860 - mae: 0.2365 - val_loss: 0.1030 - val_mae: 0.2598\n",
      "Epoch 41/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0841 - mae: 0.2336 - val_loss: 0.1014 - val_mae: 0.2561\n",
      "Epoch 42/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0849 - mae: 0.2354 - val_loss: 0.1012 - val_mae: 0.2563\n",
      "Epoch 43/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0838 - mae: 0.2365 - val_loss: 0.1015 - val_mae: 0.2570\n",
      "Epoch 44/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0792 - mae: 0.2263 - val_loss: 0.1016 - val_mae: 0.2560\n",
      "Epoch 45/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0843 - mae: 0.2384 - val_loss: 0.1010 - val_mae: 0.2552\n",
      "Epoch 46/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0819 - mae: 0.2311 - val_loss: 0.1005 - val_mae: 0.2554\n",
      "Epoch 47/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0777 - mae: 0.2248 - val_loss: 0.1032 - val_mae: 0.2574\n",
      "Epoch 48/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0861 - mae: 0.2395 - val_loss: 0.1000 - val_mae: 0.2542\n",
      "Epoch 49/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0857 - mae: 0.2361 - val_loss: 0.1012 - val_mae: 0.2552\n",
      "Epoch 50/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0867 - mae: 0.2413 - val_loss: 0.0999 - val_mae: 0.2548\n",
      "Epoch 51/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0823 - mae: 0.2310 - val_loss: 0.1005 - val_mae: 0.2560\n",
      "Epoch 52/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0789 - mae: 0.2292 - val_loss: 0.1005 - val_mae: 0.2550\n",
      "Epoch 53/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0839 - mae: 0.2351 - val_loss: 0.1004 - val_mae: 0.2550\n",
      "Epoch 54/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0824 - mae: 0.2322 - val_loss: 0.0999 - val_mae: 0.2548\n",
      "Epoch 55/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0839 - mae: 0.2365 - val_loss: 0.1006 - val_mae: 0.2563\n",
      "Epoch 56/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0816 - mae: 0.2349 - val_loss: 0.1000 - val_mae: 0.2553\n",
      "Epoch 57/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0825 - mae: 0.2343 - val_loss: 0.0999 - val_mae: 0.2555\n",
      "Epoch 58/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0770 - mae: 0.2239 - val_loss: 0.0999 - val_mae: 0.2546\n",
      "Epoch 59/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0861 - mae: 0.2360 - val_loss: 0.0996 - val_mae: 0.2545\n",
      "Epoch 60/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0807 - mae: 0.2319 - val_loss: 0.1001 - val_mae: 0.2558\n",
      "Epoch 61/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0814 - mae: 0.2331 - val_loss: 0.1000 - val_mae: 0.2557\n",
      "Epoch 62/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0769 - mae: 0.2248 - val_loss: 0.0999 - val_mae: 0.2553\n",
      "Epoch 63/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0826 - mae: 0.2333 - val_loss: 0.0995 - val_mae: 0.2541\n",
      "Epoch 64/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0811 - mae: 0.2316 - val_loss: 0.0997 - val_mae: 0.2553\n",
      "Epoch 65/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0825 - mae: 0.2344 - val_loss: 0.1017 - val_mae: 0.2562\n",
      "Epoch 66/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0837 - mae: 0.2369 - val_loss: 0.0995 - val_mae: 0.2550\n",
      "Epoch 67/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0826 - mae: 0.2341 - val_loss: 0.0997 - val_mae: 0.2546\n",
      "Epoch 68/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0823 - mae: 0.2347 - val_loss: 0.0992 - val_mae: 0.2548\n",
      "Epoch 69/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0873 - mae: 0.2402 - val_loss: 0.0990 - val_mae: 0.2540\n",
      "Epoch 70/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0824 - mae: 0.2344 - val_loss: 0.0990 - val_mae: 0.2538\n",
      "Epoch 71/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0794 - mae: 0.2278 - val_loss: 0.0996 - val_mae: 0.2553\n",
      "Epoch 72/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0827 - mae: 0.2356 - val_loss: 0.0995 - val_mae: 0.2544\n",
      "Epoch 73/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0823 - mae: 0.2340 - val_loss: 0.0997 - val_mae: 0.2551\n",
      "Epoch 74/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0843 - mae: 0.2361 - val_loss: 0.1026 - val_mae: 0.2604\n",
      "Epoch 75/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0827 - mae: 0.2312 - val_loss: 0.0998 - val_mae: 0.2546\n",
      "Epoch 76/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0836 - mae: 0.2334 - val_loss: 0.0992 - val_mae: 0.2539\n",
      "Epoch 77/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0885 - mae: 0.2397 - val_loss: 0.0994 - val_mae: 0.2552\n",
      "Epoch 78/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0841 - mae: 0.2356 - val_loss: 0.0988 - val_mae: 0.2535\n",
      "Epoch 79/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0824 - mae: 0.2327 - val_loss: 0.0992 - val_mae: 0.2538\n",
      "Epoch 80/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0824 - mae: 0.2364 - val_loss: 0.0996 - val_mae: 0.2560\n",
      "Epoch 81/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0799 - mae: 0.2295 - val_loss: 0.0994 - val_mae: 0.2540\n",
      "Epoch 82/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0814 - mae: 0.2302 - val_loss: 0.0990 - val_mae: 0.2547\n",
      "Epoch 83/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0851 - mae: 0.2370 - val_loss: 0.0995 - val_mae: 0.2542\n",
      "Epoch 84/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0849 - mae: 0.2367 - val_loss: 0.0984 - val_mae: 0.2531\n",
      "Epoch 85/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0840 - mae: 0.2350 - val_loss: 0.0987 - val_mae: 0.2541\n",
      "Epoch 86/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0830 - mae: 0.2352 - val_loss: 0.0988 - val_mae: 0.2544\n",
      "Epoch 87/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0818 - mae: 0.2319 - val_loss: 0.0982 - val_mae: 0.2527\n",
      "Epoch 88/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0805 - mae: 0.2304 - val_loss: 0.1004 - val_mae: 0.2572\n",
      "Epoch 89/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0816 - mae: 0.2297 - val_loss: 0.0987 - val_mae: 0.2537\n",
      "Epoch 90/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0811 - mae: 0.2300 - val_loss: 0.0987 - val_mae: 0.2534\n",
      "Epoch 91/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0803 - mae: 0.2322 - val_loss: 0.0986 - val_mae: 0.2534\n",
      "Epoch 92/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0818 - mae: 0.2333 - val_loss: 0.0981 - val_mae: 0.2529\n",
      "Epoch 93/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0841 - mae: 0.2357 - val_loss: 0.0983 - val_mae: 0.2535\n",
      "Epoch 94/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0789 - mae: 0.2302 - val_loss: 0.0988 - val_mae: 0.2531\n",
      "Epoch 95/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0796 - mae: 0.2271 - val_loss: 0.0985 - val_mae: 0.2542\n",
      "Epoch 96/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0744 - mae: 0.2222 - val_loss: 0.0985 - val_mae: 0.2538\n",
      "Epoch 97/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0777 - mae: 0.2245 - val_loss: 0.0982 - val_mae: 0.2532\n",
      "Epoch 98/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0817 - mae: 0.2326 - val_loss: 0.0983 - val_mae: 0.2540\n",
      "Epoch 99/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0820 - mae: 0.2288 - val_loss: 0.0980 - val_mae: 0.2522\n",
      "Epoch 100/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0767 - mae: 0.2250 - val_loss: 0.0978 - val_mae: 0.2521\n",
      "Epoch 101/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0801 - mae: 0.2299 - val_loss: 0.0979 - val_mae: 0.2523\n",
      "Epoch 102/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0813 - mae: 0.2295 - val_loss: 0.0979 - val_mae: 0.2524\n",
      "Epoch 103/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0741 - mae: 0.2221 - val_loss: 0.0980 - val_mae: 0.2528\n",
      "Epoch 104/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0795 - mae: 0.2301 - val_loss: 0.0982 - val_mae: 0.2539\n",
      "Epoch 105/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0836 - mae: 0.2323 - val_loss: 0.0983 - val_mae: 0.2540\n",
      "Epoch 106/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0799 - mae: 0.2297 - val_loss: 0.0978 - val_mae: 0.2532\n",
      "Epoch 107/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0870 - mae: 0.2388 - val_loss: 0.0983 - val_mae: 0.2540\n",
      "Epoch 108/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0830 - mae: 0.2325 - val_loss: 0.0977 - val_mae: 0.2527\n",
      "Epoch 109/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0793 - mae: 0.2271 - val_loss: 0.0978 - val_mae: 0.2527\n",
      "Epoch 110/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0747 - mae: 0.2211 - val_loss: 0.0973 - val_mae: 0.2516\n",
      "Epoch 111/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0803 - mae: 0.2313 - val_loss: 0.0974 - val_mae: 0.2521\n",
      "Epoch 112/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0797 - mae: 0.2292 - val_loss: 0.0986 - val_mae: 0.2548\n",
      "Epoch 113/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0786 - mae: 0.2277 - val_loss: 0.0976 - val_mae: 0.2522\n",
      "Epoch 114/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0800 - mae: 0.2299 - val_loss: 0.0973 - val_mae: 0.2518\n",
      "Epoch 115/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0801 - mae: 0.2311 - val_loss: 0.0972 - val_mae: 0.2519\n",
      "Epoch 116/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0786 - mae: 0.2282 - val_loss: 0.0984 - val_mae: 0.2522\n",
      "Epoch 117/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0795 - mae: 0.2256 - val_loss: 0.0973 - val_mae: 0.2518\n",
      "Epoch 118/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0800 - mae: 0.2300 - val_loss: 0.0973 - val_mae: 0.2519\n",
      "Epoch 119/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0762 - mae: 0.2235 - val_loss: 0.0971 - val_mae: 0.2514\n",
      "Epoch 120/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0771 - mae: 0.2261 - val_loss: 0.0971 - val_mae: 0.2510\n",
      "Epoch 121/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0795 - mae: 0.2301 - val_loss: 0.0971 - val_mae: 0.2519\n",
      "Epoch 122/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0799 - mae: 0.2295 - val_loss: 0.0972 - val_mae: 0.2515\n",
      "Epoch 123/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0820 - mae: 0.2327 - val_loss: 0.0976 - val_mae: 0.2532\n",
      "Epoch 124/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0790 - mae: 0.2294 - val_loss: 0.0970 - val_mae: 0.2509\n",
      "Epoch 125/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0807 - mae: 0.2327 - val_loss: 0.0968 - val_mae: 0.2510\n",
      "Epoch 126/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0764 - mae: 0.2192 - val_loss: 0.0973 - val_mae: 0.2527\n",
      "Epoch 127/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0786 - mae: 0.2278 - val_loss: 0.0969 - val_mae: 0.2518\n",
      "Epoch 128/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0778 - mae: 0.2272 - val_loss: 0.0969 - val_mae: 0.2513\n",
      "Epoch 129/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0779 - mae: 0.2270 - val_loss: 0.0971 - val_mae: 0.2520\n",
      "Epoch 130/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0795 - mae: 0.2289 - val_loss: 0.0974 - val_mae: 0.2529\n",
      "Epoch 131/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0765 - mae: 0.2240 - val_loss: 0.0968 - val_mae: 0.2518\n",
      "Epoch 132/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0795 - mae: 0.2251 - val_loss: 0.0974 - val_mae: 0.2513\n",
      "Epoch 133/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0817 - mae: 0.2311 - val_loss: 0.0967 - val_mae: 0.2514\n",
      "Epoch 134/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0798 - mae: 0.2294 - val_loss: 0.0967 - val_mae: 0.2511\n",
      "Epoch 135/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0797 - mae: 0.2309 - val_loss: 0.0965 - val_mae: 0.2505\n",
      "Epoch 136/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0812 - mae: 0.2311 - val_loss: 0.0967 - val_mae: 0.2508\n",
      "Epoch 137/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0753 - mae: 0.2231 - val_loss: 0.0965 - val_mae: 0.2507\n",
      "Epoch 138/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0834 - mae: 0.2342 - val_loss: 0.0968 - val_mae: 0.2514\n",
      "Epoch 139/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0760 - mae: 0.2215 - val_loss: 0.0966 - val_mae: 0.2508\n",
      "Epoch 140/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0810 - mae: 0.2279 - val_loss: 0.0967 - val_mae: 0.2509\n",
      "Epoch 141/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0790 - mae: 0.2290 - val_loss: 0.0967 - val_mae: 0.2516\n",
      "Epoch 142/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0771 - mae: 0.2216 - val_loss: 0.0966 - val_mae: 0.2507\n",
      "Epoch 143/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0787 - mae: 0.2288 - val_loss: 0.0963 - val_mae: 0.2508\n",
      "Epoch 144/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0814 - mae: 0.2289 - val_loss: 0.0965 - val_mae: 0.2514\n",
      "Epoch 145/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0816 - mae: 0.2298 - val_loss: 0.0965 - val_mae: 0.2512\n",
      "Epoch 146/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0797 - mae: 0.2299 - val_loss: 0.0965 - val_mae: 0.2515\n",
      "Epoch 147/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0789 - mae: 0.2283 - val_loss: 0.0967 - val_mae: 0.2519\n",
      "Epoch 148/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0788 - mae: 0.2282 - val_loss: 0.0972 - val_mae: 0.2528\n",
      "Epoch 149/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0797 - mae: 0.2268 - val_loss: 0.0966 - val_mae: 0.2518\n",
      "Epoch 150/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0795 - mae: 0.2300 - val_loss: 0.0961 - val_mae: 0.2502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ac64ee9db0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo 3 con 150 épocas\n",
    "\n",
    "modelo3.fit(X_train, y_train, epochs=150, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0817 - mae: 0.2250 \n",
      "Loss values modelo 3: [0.08308175951242447, 0.22887933254241943]\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el 3er modelo entrenado con 150 épocas\n",
    "\n",
    "loss3 = modelo3.evaluate(X_test, y_test)\n",
    "\n",
    "# Mostrar los valores mínimos de pérdida y de MAE del modelo 3\n",
    "\n",
    "print(f'Loss values modelo 3: {loss3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss y MAE de los 3 modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| MODEL | LOSS | MAE |\n",
    "| ----- | ---- | --- |\n",
    "| Modelo 1 (original) | 0.0628 | 0.1842 |\n",
    "| Modelo 2 | 0.0658 | 0.1924 |\n",
    "| Modelo 3 | 0.0817 | 0.2250 |\n",
    "\n",
    "**Nota: Modelo 1 se refiere al primer modelo generado antes de los 2 adicionales.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción de GPA para 5 estudiantes con los 3 modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Sports</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.135763</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1.989925</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>10.588715</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>16.208658</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3.576821</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>8.412605</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3.170405</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5.141922</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>10.281614</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>15.610436</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  ParentalEducation  StudyTimeWeekly  Absences  ParentalSupport  \\\n",
       "1004   15                  4         0.135763        17                2   \n",
       "196    16                  4         1.989925         0                1   \n",
       "2342   15                  0        10.588715        15                3   \n",
       "1708   18                  2        16.208658         1                3   \n",
       "435    18                  0         3.576821        27                1   \n",
       "...   ...                ...              ...       ...              ...   \n",
       "986    18                  2         8.412605        16                3   \n",
       "120    18                  3         3.170405        12                1   \n",
       "283    17                  1         5.141922         5                1   \n",
       "1740   18                  0        10.281614        10                3   \n",
       "1726   18                  0        15.610436        26                3   \n",
       "\n",
       "      Sports  GradeClass  \n",
       "1004       1         4.0  \n",
       "196        0         1.0  \n",
       "2342       0         2.0  \n",
       "1708       0         0.0  \n",
       "435        1         4.0  \n",
       "...      ...         ...  \n",
       "986        1         4.0  \n",
       "120        1         3.0  \n",
       "283        0         3.0  \n",
       "1740       0         2.0  \n",
       "1726       0         4.0  \n",
       "\n",
       "[479 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar los alumnos que pertenecen al dataset de prueba para elegir 5 de ellos\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Sports</th>\n",
       "      <th>GradeClass</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3.170405</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.174903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5.141922</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.332540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>8.412605</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.562360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.135763</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.427724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>15.610436</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.863545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  ParentalEducation  StudyTimeWeekly  Absences  ParentalSupport  \\\n",
       "120    18                  3         3.170405        12                1   \n",
       "283    17                  1         5.141922         5                1   \n",
       "986    18                  2         8.412605        16                3   \n",
       "1004   15                  4         0.135763        17                2   \n",
       "1726   18                  0        15.610436        26                3   \n",
       "\n",
       "      Sports  GradeClass       GPA  \n",
       "120        1         3.0  2.174903  \n",
       "283        0         3.0  2.332540  \n",
       "986        1         4.0  1.562360  \n",
       "1004       1         4.0  1.427724  \n",
       "1726       0         4.0  0.863545  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elegir los alumnos número 120, 283, 986, 1004 y 1726 del dataset de prueba\n",
    "\n",
    "alumnos5 = dataset.iloc[[120, 283, 986, 1004, 1726], :]\n",
    "\n",
    "alumnos5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predecir el GPA para los 5 alumnos con el primer modelo (SNN)\n",
    "\n",
    "pred_M1 = SNN.predict(alumnos5.iloc[:, :7])\n",
    "\n",
    "# Predecir GPA con el modelo 2 (modelo2)\n",
    "\n",
    "pred_M2 = modelo2.predict(alumnos5.iloc[:, :7])\n",
    "\n",
    "# Predecir GPA con el modelo 3 (modelo3)\n",
    "\n",
    "pred_M3 = modelo3.predict(alumnos5.iloc[:, :7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_M1 = pd.Series(np.reshape(pred_M1, len(pred_M1)))\n",
    "pred_M2 = pd.Series(np.reshape(pred_M2, len(pred_M2)))\n",
    "pred_M3 = pd.Series(np.reshape(pred_M3, len(pred_M3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA M1</th>\n",
       "      <th>GPA M2</th>\n",
       "      <th>GPA M3</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student_Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2.229356</td>\n",
       "      <td>2.133603</td>\n",
       "      <td>2.181287</td>\n",
       "      <td>2.174903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2.434402</td>\n",
       "      <td>2.197772</td>\n",
       "      <td>2.473202</td>\n",
       "      <td>2.332540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1.966774</td>\n",
       "      <td>1.808585</td>\n",
       "      <td>2.173240</td>\n",
       "      <td>1.562360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1.409159</td>\n",
       "      <td>1.441483</td>\n",
       "      <td>1.310229</td>\n",
       "      <td>1.427724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>0.935799</td>\n",
       "      <td>1.011831</td>\n",
       "      <td>1.163381</td>\n",
       "      <td>0.863545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GPA M1    GPA M2    GPA M3    Actual\n",
       "Student_Index                                        \n",
       "120            2.229356  2.133603  2.181287  2.174903\n",
       "283            2.434402  2.197772  2.473202  2.332540\n",
       "986            1.966774  1.808585  2.173240  1.562360\n",
       "1004           1.409159  1.441483  1.310229  1.427724\n",
       "1726           0.935799  1.011831  1.163381  0.863545"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_3modelos_5alumnos = pd.DataFrame({\"GPA M1\": pred_M1, \"GPA M2\": pred_M2, \"GPA M3\": pred_M3, \n",
    "                                       \"Actual\": pd.Series(dataset[\"GPA\"][[120, 283, 986, 1004, 1726]]).reset_index(drop = True)})\n",
    "\n",
    "pred_3modelos_5alumnos.index = [120, 283, 986, 1004, 1726]\n",
    "\n",
    "pred_3modelos_5alumnos.index.name = \"Student_Index\"\n",
    "\n",
    "pred_3modelos_5alumnos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, es importante mencionar que de acuerdo a las tablas comparativas anteriores, aquel modelo que resultó ser el mejor, es el modelo 1 que corresponde a la red neuronal secuencial conformada por una capa de 64 unidades y otra capa oculta adicional de 32 unidades y entrenada con un optimizador de tipo Adam y un total de 50 épocas o iteraciones, esto principalmente debido a que éste modelo tiene el menor valor de pérdida (Loss) y de MAE, siendo éstos valores de 0.0628 y 0.1842, respectivamente, superando así por poco a los modelos 2 y 3 generados posteriormente, por lo que el modelo 1 pasa a ser el mejor de los 3 puestos a prueba para predecir de la manera más precisa y confiable posible, el GPA de los alumnos. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
